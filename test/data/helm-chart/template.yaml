# yamllint disable rule:line-length
# yamllint disable rule:trailing-spaces
---
# Source: redhat-trusted-application-pipeline/templates/developer-hub/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: rhdh-kubernetes-plugin
  namespace: rhtap
---
# Source: redhat-trusted-application-pipeline/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: helm-manager
  namespace: rhtap
---
# Source: redhat-trusted-application-pipeline/templates/developer-hub/serviceaccount.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: rhdh-kubernetes-plugin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: view
subjects:
  - kind: ServiceAccount
    name: rhdh-kubernetes-plugin
    namespace: rhtap
---
# Source: redhat-trusted-application-pipeline/templates/serviceaccount.yaml
# The ServiceAccount needs to be able to manage resources that
# might not be declated until after Subscriptions have been
# deployed (e.g. TektonConfig).
#
# If the ServiceAccount did not have admin privilegers, it
# would need the permission to edit roles. An attacker
# getting access to this ServiceAccount would be able
# to grant any role to any account.
# Therefore the attack surface is not increased by giving
# the admin role to the ServiceAccount.
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: helm-manager-admin
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: cluster-admin
subjects:
  - kind: ServiceAccount
    name: helm-manager
    namespace: rhtap
---
# Source: redhat-trusted-application-pipeline/templates/openshift-gitops/subscription.yaml
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  annotations:
    helm.sh/resource-policy: keep
  name: openshift-gitops-operator
  namespace: openshift-operators
spec:
  channel: gitops-1.12
  installPlanApproval: Automatic
  name: openshift-gitops-operator
  source: redhat-operators
  sourceNamespace: openshift-marketplace
  config:
    env:
      - name: ARGOCD_CLUSTER_CONFIG_NAMESPACES
        value: openshift-gitops,rhtap
---
# Source: redhat-trusted-application-pipeline/templates/openshift-pipelines/subscription.yaml
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  annotations:
    helm.sh/resource-policy: keep
  name: openshift-pipelines-operator
  namespace: openshift-operators
spec:
  channel: pipelines-1.14
  installPlanApproval: Automatic
  name: openshift-pipelines-operator-rh
  source: redhat-operators
  sourceNamespace: openshift-marketplace
---
# Source: redhat-trusted-application-pipeline/templates/trusted-artifact-signer/subscription.yaml
apiVersion: operators.coreos.com/v1alpha1
kind: Subscription
metadata:
  annotations:
    helm.sh/resource-policy: keep
  labels:
    operators.coreos.com/rhtas-operator.openshift-operators: ""
  name: rhtas-operator
  namespace: openshift-operators
spec:
  channel: stable
  installPlanApproval: Automatic
  name: rhtas-operator
  source: redhat-operators
  sourceNamespace: openshift-marketplace
  startingCSV: rhtas-operator.v0.0.2
---
# Source: redhat-trusted-application-pipeline/templates/configure.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: "rhtap-installer-configure"
  labels:
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "installer"
    app.kubernetes.io/version: 1.1.0
    helm.sh/chart: "redhat-trusted-application-pipeline-0.1.0"
  annotations:
    # This is what defines this resource as a hook. Without this line, the
    # job is considered part of the release.
    "helm.sh/hook": post-install, post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation
spec:
  template:
    metadata:
      name: "installer-configure"
      labels:
        app.kubernetes.io/managed-by: "Helm"
        app.kubernetes.io/instance: "installer"
        helm.sh/chart: "redhat-trusted-application-pipeline-0.1.0"
    spec:
      containers:
      
                
        - name: configure-acs
          image: "registry.redhat.io/openshift4/ose-tools-rhel8:latest"
          command:
            - /bin/bash
            - -c
            - |
              set -o errexit
              set -o nounset
              set -o pipefail
            
        
              echo
              echo "Configuration successful"
        
                
        
        - name: configure-developer-hub
          image: "registry.redhat.io/openshift4/ose-tools-rhel8:latest"
          command:
            - /bin/bash
            - -c
            - |
              set -o errexit
              set -o nounset
              set -o pipefail
            
        
              echo -n "Installing utils: "
              dnf install -y diffutils > /dev/null 2>/dev/null
              echo -n "."
        
              # Installing Helm...
              curl --fail --silent --show-error --location \
                https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 \
                  | bash >/dev/null
              echo "OK"
        
              YQ_VERSION="v4.40.5"
              curl --fail --location --output "/usr/bin/yq" --silent --show-error "https://github.com/mikefarah/yq/releases/download/${YQ_VERSION}/yq_linux_amd64"
              chmod +x "/usr/bin/yq"
        
              CHART="rhtap"
              NAMESPACE="rhtap"
        
              echo -n "* Generating 'app-config.extra.yaml': "
              APPCONFIGEXTRA="app-config.extra.yaml"
              touch "$APPCONFIGEXTRA"
              echo -n "."
            
              cat << _EOF_ >> "$APPCONFIGEXTRA"
              auth:
                environment: production
                providers:
                  github:
                    production:
                      clientId: ${GITHUB__APP__CLIENT_ID}
                      clientSecret: ${GITHUB__APP__CLIENT_SECRET}
                  gitlab:
                    production:
                      clientId: ${GITLAB__OAUTH__CLIENT_ID}
                      clientSecret: ${GITLAB__OAUTH__CLIENT_SECRET}
              catalog:
                locations:
                - target: ${DEVELOPER_HUB__CATALOG__URL}
                  type: url
                rules:
                - allow:
                  - Component
                  - System
                  - Group
                  - Resource
                  - Location
                  - Template
                  - API
              integrations:
                github:
                - apps:
                  - appId: ${GITHUB__APP__APP_ID}
                    clientId: ${GITHUB__APP__CLIENT_ID}
                    clientSecret: ${GITHUB__APP__CLIENT_SECRET}
                    privateKey: |
                      ${GITHUB__APP__PRIVATE_KEY}
                    webhookSecret: ${GITHUB__APP__WEBHOOK_SECRET}
                    webhookUrl: GITHUB__APP__WEBHOOK_URL
                  host: github.com
                gitlab:
                - host: gitlab.com
                  token: ${GITLAB_TOKEN}
              techdocs:
                builder: local
                generator:
                  runIn: local
                publisher:
                  type: local
              _EOF_
              echo -n "."
            
        
              # ArgoCD integration
              while [ "$(kubectl get secret "$CHART-argocd-secret" --ignore-not-found -o name | wc -l)" != "1" ]; do
                echo -ne "_"
                sleep 2
              done
              kubectl get secret "$CHART-argocd-secret" -o yaml > argocd_secret.yaml
              echo -n "."
        
              ARGOCD_API_TOKEN="$(yq '.data.api-token | @base64d' argocd_secret.yaml)"
              ARGOCD_HOSTNAME="$(yq '.data.hostname | @base64d' argocd_secret.yaml)"
              ARGOCD_PASSWORD="$(yq '.data.password | @base64d' argocd_secret.yaml)"
              ARGOCD_USER="$(yq '.data.user | @base64d' argocd_secret.yaml)"
              cat << _EOF_ >> "$APPCONFIGEXTRA"
              argocd:
                username: $ARGOCD_USER
                password: $ARGOCD_PASSWORD
                waitCycles: 25
                appLocatorMethods:
                  - type: 'config'
                    instances:
                      - name: default
                        url: https://$ARGOCD_HOSTNAME
                        token: $ARGOCD_API_TOKEN
              _EOF_
        
              # Tekton integration
              while [ "$(kubectl get secret "$CHART-pipelines-secret" --ignore-not-found -o name | wc -l)" != "1" ]; do
                echo -ne "_"
                sleep 2
              done
              PIPELINES_PAC_URL="$(kubectl get secret "$CHART-pipelines-secret" -o yaml | yq '.data.webhook-url | @base64d')"
              yq -i ".integrations.github[0].apps[0].webhookUrl = \"$PIPELINES_PAC_URL\"" "$APPCONFIGEXTRA"
              echo "OK"
        
              echo -n "* Generating values.yaml: "
              HELM_VALUES="/tmp/developer-hub-values.yaml"
            
              cat <<EOF >${HELM_VALUES}
              global:
                dynamic:
                  includes:
                  - dynamic-plugins.default.yaml
                  plugins:
                  - disabled: false
                    package: ./dynamic-plugins/dist/roadiehq-backstage-plugin-argo-cd
                    pluginConfig:
                      dynamicPlugins:
                        frontend:
                          roadiehq.backstage-plugin-argo-cd:
                            mountPoints:
                            - config:
                                if:
                                  allOf:
                                  - isArgocdAvailable
                                layout:
                                  gridColumnEnd:
                                    lg: span 8
                                    xs: span 12
                              importName: EntityArgoCDOverviewCard
                              mountPoint: entity.page.overview/cards
                            - config:
                                if:
                                  allOf:
                                  - isArgocdAvailable
                                layout:
                                  gridColumn: 1 / -1
                              importName: EntityArgoCDHistoryCard
                              mountPoint: entity.page.cd/cards
                  - disabled: false
                    package: ./dynamic-plugins/dist/roadiehq-backstage-plugin-argo-cd-backend-dynamic
                  - disabled: false
                    package: ./dynamic-plugins/dist/roadiehq-scaffolder-backend-argocd-dynamic
                  - disabled: false
                    package: ./dynamic-plugins/dist/backstage-plugin-techdocs-backend-dynamic
                  - disabled: false
                    package: ./dynamic-plugins/dist/backstage-plugin-techdocs
                  - disabled: false
                    package: ./dynamic-plugins/dist/backstage-plugin-kubernetes
                  - disabled: false
                    package: ./dynamic-plugins/dist/backstage-plugin-kubernetes-backend-dynamic
                    pluginConfig:
                      kubernetes:
                        clusterLocatorMethods:
                        - clusters:
                          - authProvider: serviceAccount
                            name: rhdh-kubernetes-plugin
                            serviceAccountToken: <token>
                            skipTLSVerify: true
                            url: https://kubernetes.default.svc
                          type: config
                        customResources:
                        - apiVersion: v1
                          group: route.openshift.io
                          plural: routes
                        - apiVersion: v1
                          group: tekton.dev
                          plural: pipelineruns
                        - apiVersion: v1
                          group: tekton.dev
                          plural: taskruns
                        serviceLocatorMethod:
                          type: multiTenant
                  - disabled: false
                    package: ./dynamic-plugins/dist/janus-idp-backstage-plugin-quay
                  - disabled: false
                    package: ./dynamic-plugins/dist/janus-idp-backstage-plugin-tekton
                    pluginConfig:
                      dynamicPlugins:
                        frontend:
                          janus-idp.backstage-plugin-tekton:
                            mountPoints:
                            - config:
                                if:
                                  allOf:
                                  - isTektonCIAvailable
                                layout:
                                  gridColumn: 1 / -1
                                  gridRowStart: 1
                              importName: TektonCI
                              mountPoint: entity.page.ci/cards
                  - disabled: false
                    package: ./dynamic-plugins/dist/janus-idp-backstage-plugin-topology
              upstream:
                backstage:
                  extraAppConfig:
                  - configMapRef: redhat-developer-hub-app-config-extra
                    filename: app-config.extra.yaml
              EOF
            
              echo -n "."
              KUBERNETES_CLUSTER_FQDN="$(
                kubectl get routes -n openshift-pipelines pipelines-as-code-controller -o jsonpath='{.spec.host}' | \
                cut -d. -f 2-
              )"
              export KUBERNETES_CLUSTER_FQDN
              yq --inplace '.global.clusterRouterBase = strenv(KUBERNETES_CLUSTER_FQDN)' "$HELM_VALUES"
              echo "OK"
        
              
              ################################################################################
              # Tekton plugin configuration
              ################################################################################
              export K8S_SA_TOKEN=$(
                SECRET_NAME=$(kubectl get secrets --namespace "$NAMESPACE" -o name | grep rhdh-kubernetes-plugin-token- | cut -d/ -f2 | head -1)
                kubectl get secret --namespace "$NAMESPACE" "$SECRET_NAME" -o jsonpath={.data.token} | base64 -d
              )
              yq -i '
                (
                  (
                    (.global.dynamic.plugins[] | select(.package == "./dynamic-plugins/dist/backstage-plugin-kubernetes-backend-dynamic")) |
                    .pluginConfig.kubernetes.clusterLocatorMethods[].clusters[]
                  ) |
                  select(.name == "rhdh-kubernetes-plugin") |
                  .serviceAccountToken
                ) = strenv(K8S_SA_TOKEN)
              ' "$HELM_VALUES"
              
        
              echo -n "* Installing Developer Hub: "
              kubectl create configmap redhat-developer-hub-app-config-extra \
                --from-file=app-config.extra.yaml="$APPCONFIGEXTRA" \
                -o yaml \
                --dry-run=client | kubectl apply -f - >/dev/null
              echo -n "."
              helm repo add developer-hub https://charts.openshift.io/ >/dev/null
              echo -n "."
              if ! helm upgrade \
                --install \
                --devel \
                --namespace=${NAMESPACE} \
                --values="$HELM_VALUES" \
                --version=~1.1 \
                redhat-developer-hub \
                developer-hub/redhat-developer-hub >/dev/null; then
                echo "ERROR while installing chart!"
                exit 1
              fi
              echo "OK"
        
              echo -n "* Waiting for route: "
              until kubectl get route "redhat-developer-hub" -o name >/dev/null ; do
                echo -n "."
                sleep 3
              done
              HOSTNAME="$(kubectl get routes "redhat-developer-hub" -o jsonpath="{.spec.host}")"
              echo -n "."
              if [ "$(kubectl get secret "$CHART-developer-hub-secret" -o name --ignore-not-found | wc -l)" = "0" ]; then
                kubectl create secret generic "$CHART-developer-hub-secret" \
                  --from-literal="hostname=$HOSTNAME" >/dev/null
              fi
              echo "OK"
        
              # Wait for the UI to fully boot once before modifying the configuration.
              # This should avoid issues with DB migrations being interrupted and generating locks.
              # Once RHIDP-1691 is solved that safeguard could be removed.
              echo -n "* Waiting for UI: "
              until curl --fail --insecure --location --output /dev/null --silent "https://$HOSTNAME"; do
                echo -n "_"
                sleep 3
              done
              echo "OK"
        
              
              ################################################################################
              # Configure TLS
              ################################################################################
              echo -n "* Waiting for deployment: "
              until kubectl get deployment redhat-developer-hub -o name >/dev/null ; do
                echo -n "_"
                sleep 3
              done
              echo "OK"
              
              ORIGNAL_POD=$(kubectl get pods -l app.kubernetes.io/name=developer-hub -o name)
              
              DEPLOYMENT="/tmp/deployment.yaml"
              DEPLOYMENT_PATCHED="/tmp/deployment.patched.yaml"
              oc get deployment/redhat-developer-hub -o yaml >"$DEPLOYMENT"
              cp "$DEPLOYMENT" "$DEPLOYMENT_PATCHED"
              
              echo -n "* Configuring TLS:"
              # Update env var.
              if [ "$(yq '.spec.template.spec.containers[0].env[] | select(.name == "NODE_EXTRA_CA_CERTS") | length' "$DEPLOYMENT_PATCHED")" == "2" ]; then
                  YQ_EXPRESSION='
              (
                  .spec.template.spec.containers[].env[] |
                  select(.name == "NODE_EXTRA_CA_CERTS") | .value
              ) = "/ingress-cert/ca.crt"
              '
              else
                  YQ_EXPRESSION='.spec.template.spec.containers[0].env += {"name": "NODE_EXTRA_CA_CERTS", "value": "/ingress-cert/ca.crt"}'
              fi
              yq --inplace "$YQ_EXPRESSION" "$DEPLOYMENT_PATCHED"
              echo -n "."
              # Update volume mount
              if [ "$(yq '.spec.template.spec.containers[0].volumeMounts[] | select(.name == "kube-root-ca") | length' "$DEPLOYMENT_PATCHED")" == "2" ]; then
                  YQ_EXPRESSION='
              (
                  .spec.template.spec.containers[].volumeMounts[] |
                  select(.name == "kube-root-ca") | .mountPath
              ) = "/ingress-cert"
              '
              else
                  YQ_EXPRESSION='.spec.template.spec.containers[0].volumeMounts += {"name": "kube-root-ca", "mountPath": "/ingress-cert"}'
              fi
              yq --inplace "$YQ_EXPRESSION" "$DEPLOYMENT_PATCHED"
              echo -n "."
              # Update volume
              if [ "$(yq '.spec.template.spec.volumes[] | select(.name == "kube-root-ca") | length' "$DEPLOYMENT_PATCHED")" == "2" ]; then
                  YQ_EXPRESSION='
              (
                  .spec.template.spec.volumes[] |
                  select(.name == "kube-root-ca") | .configMap
              ) = {"name": "kube-root-ca.crt", "defaultMode": 420}
              '
              else
                  YQ_EXPRESSION='.spec.template.spec.volumes += {"name": "kube-root-ca", "configMap": {"name": "kube-root-ca.crt", "defaultMode": 420}}'
              fi
              yq --inplace "$YQ_EXPRESSION" "$DEPLOYMENT_PATCHED"
              echo "OK"
              
              echo -n "* Updating deployment: "
              yq -i 'sort_keys(..)' "$DEPLOYMENT"
              yq -i 'sort_keys(..)' "$DEPLOYMENT_PATCHED"
              if ! diff --brief "$DEPLOYMENT" "$DEPLOYMENT_PATCHED" >/dev/null; then
                  oc apply -f "$DEPLOYMENT_PATCHED" >/dev/null 2>&1
              
                  # Wait for the configuration to be deployed
                  while kubectl get "$ORIGNAL_POD" -o name >/dev/null 2>&1 ; do
                      echo -n "_"
                      sleep 2
                  done
                  echo "OK"
              else
                  echo "Configuration already up to date"
              fi
              
        
              echo -n "* Waiting for UI: "
              until curl --fail --insecure --location --output /dev/null --silent "https://$HOSTNAME"; do
                echo -n "_"
                sleep 3
              done
              echo "OK"
        
              echo
              echo "Configuration successful"
        
        
                
        - name: configure-gitops
          image: "registry.redhat.io/openshift4/ose-tools-rhel8:latest"
          command:
            - /bin/sh
            - -c
            - |
              set -o errexit
              set -o nounset
              set -o pipefail
            
        
              echo -n "* Installing 'argocd' CLI: "
              curl -sSL -o argocd https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64
              chmod 555 argocd
              ./argocd version --client | head -1 | cut -d' ' -f2
        
              CRD="argocds"
              echo -n "* Waiting for '$CRD' CRD: "
              while [ $(kubectl api-resources | grep -c "^$CRD ") = "0" ] ; do
                echo -n "."
                sleep 3
              done
              echo "OK"
        
              #
              # All actions must be idempotent
              #
              CHART="rhtap"
              NAMESPACE="rhtap"
              RHTAP_ARGOCD_INSTANCE="$CHART-argocd"
        
              echo -n "* Waiting for gitops operator deployment: "
              until kubectl get argocds.argoproj.io -n openshift-gitops openshift-gitops -o jsonpath={.status.phase} | grep -q "^Available$"; do
                echo -n "_"
                sleep 2
              done
              echo "OK"
        
              echo -n "* Creating ArgoCD instance for RHTAP: "
              cat <<EOF | kubectl apply -n "$NAMESPACE" -f - >/dev/null
                    
              ---
              apiVersion: argoproj.io/v1beta1
              kind: ArgoCD
              metadata:
                name: rhtap-argocd
              spec:
                server:
                  autoscale:
                    enabled: false
                  grpc:
                    ingress:
                      enabled: false
                  ingress:
                    enabled: false
                  resources:
                    limits:
                      cpu: 500m
                      memory: 256Mi
                    requests:
                      cpu: 125m
                      memory: 128Mi
                  route:
                    enabled: true
                    tls:
                      insecureEdgeTerminationPolicy: Redirect
                      termination: reencrypt
                  service:
                    type: ''
                grafana:
                  enabled: false
                  ingress:
                    enabled: false
                  resources:
                    limits:
                      cpu: 500m
                      memory: 256Mi
                    requests:
                      cpu: 250m
                      memory: 128Mi
                  route:
                    enabled: false
                monitoring:
                  enabled: false
                notifications:
                  enabled: false
                prometheus:
                  enabled: false
                  ingress:
                    enabled: false
                  route:
                    enabled: false
                initialSSHKnownHosts: {}
                sso:
                  dex:
                    openShiftOAuth: true
                    resources:
                      limits:
                        cpu: 500m
                        memory: 256Mi
                      requests:
                        cpu: 250m
                        memory: 128Mi
                  provider: dex
                applicationSet:
                  resources:
                    limits:
                      cpu: '2'
                      memory: 1Gi
                    requests:
                      cpu: 250m
                      memory: 512Mi
                  webhookServer:
                    ingress:
                      enabled: false
                    route:
                      enabled: false
                rbac:
                  defaultPolicy: ''
                  policy: |
                    g, system:cluster-admins, role:admin
                    g, cluster-admins, role:admin
                  scopes: '[groups]'
                repo:
                  resources:
                    limits:
                      cpu: '1'
                      memory: 1Gi
                    requests:
                      cpu: 250m
                      memory: 256Mi
                resourceExclusions: |
                  - apiGroups:
                    - tekton.dev
                    clusters:
                    - '*'
                    kinds:
                    - TaskRun
                    - PipelineRun
                ha:
                  enabled: false
                  resources:
                    limits:
                      cpu: 500m
                      memory: 256Mi
                    requests:
                      cpu: 250m
                      memory: 128Mi
                tls:
                  ca: {}
                redis:
                  resources:
                    limits:
                      cpu: 500m
                      memory: 256Mi
                    requests:
                      cpu: 250m
                      memory: 128Mi
                controller:
                  processors: {}
                  resources:
                    limits:
                      cpu: "2"
                      memory: 6Gi
                    requests:
                      cpu: "1"
                      memory: 3Gi
                extraConfig:
                  accounts.admin: apiKey, login
              
              EOF
              until kubectl get argocds.argoproj.io -n "$NAMESPACE" "$RHTAP_ARGOCD_INSTANCE" --ignore-not-found -o jsonpath={.status.phase} | grep -q "^Available$"; do
                echo -n "_"
                sleep 2
              done
              echo -n "."
              until kubectl get route -n "$NAMESPACE" "$RHTAP_ARGOCD_INSTANCE-server" >/dev/null 2>&1; do
                echo -n "_"
                sleep 2
              done
              echo "OK"
        
              echo -n "* ArgoCD admin user: "
              if [ "$(kubectl get secret "$RHTAP_ARGOCD_INSTANCE-secret" -o name --ignore-not-found | wc -l)" = "0" ]; then
                  ARGOCD_HOSTNAME="$(kubectl get route -n "$NAMESPACE" "$RHTAP_ARGOCD_INSTANCE-server" --ignore-not-found -o jsonpath={.spec.host})"
                  echo -n "."
                  ARGOCD_PASSWORD="$(kubectl get secret -n "$NAMESPACE" "$RHTAP_ARGOCD_INSTANCE-cluster" -o jsonpath="{.data.admin\.password}" | base64 --decode)"
                  echo -n "."
                  ./argocd login "$ARGOCD_HOSTNAME" --grpc-web --insecure --username admin --password "$ARGOCD_PASSWORD" >/dev/null
                  echo -n "."
                  ARGOCD_API_TOKEN="$(./argocd account generate-token --account "admin")"
                  echo -n "."
                  kubectl create secret generic "$RHTAP_ARGOCD_INSTANCE-secret" \
                    --from-literal="api-token=$ARGOCD_API_TOKEN" \
                    --from-literal="hostname=$ARGOCD_HOSTNAME" \
                    --from-literal="password=$ARGOCD_PASSWORD" \
                    --from-literal="user=admin" \
                    > /dev/null
              fi
              echo "OK"
        
                    
              echo -n "* Waiting for openshift-pipelines: "
              while ! kubectl get namespace openshift-pipelines --ignore-not-found > /dev/null; do
                echo -n "."
                sleep 2
              done
              echo "OK"
              
              CRDS=( pipelines tasks )
              for CRD in "${CRDS[@]}"; do
                echo -n "* Waiting for '$CRD' CRD: "
                while [ $(kubectl api-resources | grep -c "^$CRD ") = "0" ] ; do
                  echo -n "."
                  sleep 2
                done
                echo "OK"
              done
              
              echo -n "* Waiting for openshift-pipelines webhook service: "
              while true; do
                # Try instanciating a task
                cat << EOF | kubectl apply -f - --dry-run=server >/dev/null 2>&1 && break
              apiVersion: tekton.dev/v1
              kind: Task
              metadata:
                name: deleteme-task
              spec:
                description: >-
                  Test task to validate that Tekton is installed.
                steps:
                  - image: "registry.redhat.io/openshift4/ose-tools-rhel8:latest"
                    name: setup
                    script: |
                      #!/usr/bin/env bash
                      echo "OK"
                    workingDir: /tmp
              EOF
                echo -n "."
                sleep 2
              done
              echo "OK"
              
        
              echo -n "* Configuring Tasks: "
              cat << EOF | kubectl apply -f - >/dev/null
                    
              apiVersion: tekton.dev/v1
              kind: Task
              metadata:
                name: argocd-login-check
              spec:
                description: >-
                  Check the argocd login credentials.
                steps:
                  - env:
                    - name: ARGOCD_HOSTNAME
                      valueFrom:
                        secretKeyRef:
                          name: rhtap-argocd-secret
                          key: hostname
                    - name: ARGOCD_PASSWORD
                      valueFrom:
                        secretKeyRef:
                          name: rhtap-argocd-secret
                          key: password
                    - name: ARGOCD_USER
                      valueFrom:
                        secretKeyRef:
                          name: rhtap-argocd-secret
                          key: user
                    image: registry.access.redhat.com/ubi9/ubi-minimal
                    name: check-argocd-login
                    script: |
                      #!/usr/bin/env bash
                      set -o errexit
                      set -o nounset
                      set -o pipefail
              
                      echo -n "* Installing 'argocd' CLI: "
                      curl -sSL -o argocd https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64
                      chmod 555 argocd
                      ./argocd version --client | head -1 | cut -d' ' -f2
              
                      ./argocd login "\$ARGOCD_HOSTNAME" --grpc-web --insecure --username "\$ARGOCD_USER" --password "\$ARGOCD_PASSWORD"
                    workingDir: /tmp
              
              EOF
              echo "OK"
        
              echo
              echo "Configuration successful"
        
                
        - name: configure-namespace
          image: "registry.redhat.io/openshift4/ose-tools-rhel8:latest"
          command:
            - /bin/bash
            - -c
            - |
              set -o errexit
              set -o nounset
              set -o pipefail
            
        
                    
              echo -n "* Waiting for openshift-pipelines: "
              while ! kubectl get namespace openshift-pipelines --ignore-not-found > /dev/null; do
                echo -n "."
                sleep 2
              done
              echo "OK"
              
              CRDS=( pipelines tasks )
              for CRD in "${CRDS[@]}"; do
                echo -n "* Waiting for '$CRD' CRD: "
                while [ $(kubectl api-resources | grep -c "^$CRD ") = "0" ] ; do
                  echo -n "."
                  sleep 2
                done
                echo "OK"
              done
              
              echo -n "* Waiting for openshift-pipelines webhook service: "
              while true; do
                # Try instanciating a task
                cat << EOF | kubectl apply -f - --dry-run=server >/dev/null 2>&1 && break
              apiVersion: tekton.dev/v1
              kind: Task
              metadata:
                name: deleteme-task
              spec:
                description: >-
                  Test task to validate that Tekton is installed.
                steps:
                  - image: "registry.redhat.io/openshift4/ose-tools-rhel8:latest"
                    name: setup
                    script: |
                      #!/usr/bin/env bash
                      echo "OK"
                    workingDir: /tmp
              EOF
                echo -n "."
                sleep 2
              done
              echo "OK"
              
        
              CHART="rhtap"
              NAMESPACE="rhtap"
        
              echo -n "* Configuring Tasks: "
              while ! kubectl get secrets -n openshift-pipelines signing-secrets >/dev/null 2>&1; do
                echo -n "_"
                sleep 2
              done
              echo -n "."
              COSIGN_SIGNING_PUBLIC_KEY=""
              while [ -z "${COSIGN_SIGNING_PUBLIC_KEY:-}" ]; do
                echo -n "_"
                sleep 2
                COSIGN_SIGNING_PUBLIC_KEY=$(kubectl get secrets -n openshift-pipelines signing-secrets -o jsonpath='{.data.cosign\.pub}' 2>/dev/null)
              done
              cat << EOF | kubectl apply -f - >/dev/null
                      
                apiVersion: tekton.dev/v1
                kind: Task
                metadata:
                  name: rhtap-dev-namespace-setup
                  annotations:
                    helm.sh/chart: "redhat-trusted-application-pipeline-0.1.0"
                spec:
                  description: >-
                    Create the required resources for redhat-trusted-application-pipeline tasks to run in a namespace.
                  params:
                    - default: \${GITOPS__GIT_TOKEN}
                      description: |
                        Git token
                      name: git_token
                      type: string
                    
                    
                    
                    
                    - default: "\${GITLAB_TOKEN}"
                      description: |
                        GitLab Personal Access Token
                      name: gitlab_token
                      type: string
                    - default: "\${GITHUB__APP__WEBHOOK_SECRET}"
                      description: |
                        Pipelines as Code webhook secret
                      name: pipelines_webhook_secret
                      type: string
                    - default: \${QUAY__DOCKERCONFIGJSON}
                      description: |
                        Image registry token
                      name: quay_dockerconfigjson
                      type: string
                    - default: \${ACS__CENTRAL_ENDPOINT}
                      description: |
                        StackRox Central address:port tuple
                        (example - rox.stackrox.io:443)
                      name: acs_central_endpoint
                      type: string
                    - default: \${ACS__API_TOKEN}
                      description: |
                        StackRox API token with CI permissions
                      name: acs_api_token
                      type: string
                  steps:
                    - env:
                      - name: GIT_TOKEN
                        value: \$(params.git_token)
                      - name: GITLAB_TOKEN
                        value: \$(params.gitlab_token)
                      - name: PIPELINES_WEBHOOK_SECRET
                        value: \$(params.pipelines_webhook_secret)
                      - name: QUAY_DOCKERCONFIGJSON
                        value: \$(params.quay_dockerconfigjson)
                      - name: ROX_API_TOKEN
                        value: \$(params.acs_api_token)
                      - name: ROX_ENDPOINT
                        value: \$(params.acs_central_endpoint)
                      image: "registry.redhat.io/openshift4/ose-tools-rhel8:latest"
                      name: setup
                      script: |
                        #!/usr/bin/env bash
                        set -o errexit
                        set -o nounset
                        set -o pipefail
                      
                
                        SECRET_NAME="cosign-pub"
                        if [ -n "$COSIGN_SIGNING_PUBLIC_KEY" ]; then
                          echo -n "* \$SECRET_NAME secret: "
                          cat <<EOF | kubectl apply -f - >/dev/null
                        apiVersion: v1
                        data:
                          cosign.pub: $COSIGN_SIGNING_PUBLIC_KEY
                        kind: Secret
                        metadata:
                          labels:
                            app.kubernetes.io/instance: default
                            app.kubernetes.io/part-of: tekton-chains
                            helm.sh/chart: redhat-trusted-application-pipeline-0.1.0
                            operator.tekton.dev/operand-name: tektoncd-chains
                          name: \$SECRET_NAME
                        type: Opaque
                        EOF
                          echo "OK"
                        fi
                
                        SECRET_NAME="gitlab-auth-secret"
                        if [ -n "\$GITLAB_TOKEN" ]; then
                          echo -n "* \$SECRET_NAME secret: "
                          kubectl create secret generic "\$SECRET_NAME" \
                            --from-literal=password=\$GITLAB_TOKEN \
                            --from-literal=username=oauth2 \
                            --type=kubernetes.io/basic-auth \
                            --dry-run=client -o yaml | kubectl apply --filename - --overwrite=true >/dev/null
                          kubectl annotate secret "\$SECRET_NAME" "helm.sh/chart=redhat-trusted-application-pipeline-0.1.0" >/dev/null
                          echo "OK"
                        fi
                
                        SECRET_NAME="gitops-auth-secret"
                        if [ -n "\$GIT_TOKEN" ]; then
                          echo -n "* \$SECRET_NAME secret: "
                          kubectl create secret generic "\$SECRET_NAME" \
                            --from-literal=password=\$GIT_TOKEN \
                            --type=kubernetes.io/basic-auth \
                            --dry-run=client -o yaml | kubectl apply --filename - --overwrite=true >/dev/null
                          kubectl annotate secret "\$SECRET_NAME" "helm.sh/chart=redhat-trusted-application-pipeline-0.1.0" >/dev/null
                          echo "OK"
                        fi
                
                        SECRET_NAME="pipelines-secret"
                        if [ -n "\$PIPELINES_WEBHOOK_SECRET" ]; then
                          echo -n "* \$SECRET_NAME secret: "
                          kubectl create secret generic "\$SECRET_NAME" \
                            --from-literal=webhook.secret=\$PIPELINES_WEBHOOK_SECRET \
                            --dry-run=client -o yaml | kubectl apply --filename - --overwrite=true >/dev/null
                          kubectl annotate secret "\$SECRET_NAME" "helm.sh/chart=redhat-trusted-application-pipeline-0.1.0" >/dev/null
                          echo "OK"
                        fi
                        
                        SECRET_NAME="rhtap-image-registry-token"
                        if [ -n "\$QUAY_DOCKERCONFIGJSON" ]; then
                          echo -n "* \$SECRET_NAME secret: "
                          DATA=$(mktemp)
                          echo -n "\$QUAY_DOCKERCONFIGJSON" >"\$DATA"
                          kubectl create secret docker-registry "\$SECRET_NAME" \
                            --from-file=.dockerconfigjson="\$DATA" --dry-run=client -o yaml | \
                            kubectl apply --filename - --overwrite=true >/dev/null
                          rm "\$DATA"
                          echo -n "."
                          kubectl annotate secret "\$SECRET_NAME" "helm.sh/chart=redhat-trusted-application-pipeline-0.1.0" >/dev/null
                          echo -n "."
                          while ! kubectl get serviceaccount pipeline >/dev/null &>2; do
                            sleep 2
                            echo -n "_"
                          done
                          for SA in default pipeline; do
                            kubectl patch serviceaccounts "\$SA" --patch "
                          secrets:
                            - name: \$SECRET_NAME
                          imagePullSecrets:
                            - name: \$SECRET_NAME
                          " >/dev/null
                            echo -n "."
                          done
                          echo "OK"
                        fi
                        
                        SECRET_NAME="rox-api-token"
                        if [ -n "\$ROX_API_TOKEN" ] && [ -n "\$ROX_ENDPOINT" ]; then
                          echo -n "* \$SECRET_NAME secret: "
                          kubectl create secret generic "\$SECRET_NAME" \
                            --from-literal=rox-api-endpoint=\$ROX_ENDPOINT \
                            --from-literal=rox-api-token=\$ROX_API_TOKEN \
                            --dry-run=client -o yaml | kubectl apply --filename - --overwrite=true >/dev/null
                          kubectl annotate secret "\$SECRET_NAME" "helm.sh/chart=redhat-trusted-application-pipeline-0.1.0" >/dev/null
                          echo "OK"
                        fi
                
                        echo
                        echo "Namespace is ready to execute redhat-trusted-application-pipeline pipelines"
                      workingDir: /tmp
                
              EOF
              echo -n "."
              cat << EOF | kubectl apply -f - >/dev/null
                      
                apiVersion: tekton.dev/v1
                kind: Task
                metadata:
                  name: rhtap-pe-info
                  annotations:
                    helm.sh/chart: "redhat-trusted-application-pipeline-0.1.0"
                spec:
                  description: >-
                    Display the configuration information needed by the Platform
                    Engineer to configure the RHDH.
                  steps:
                    - env:
                      - name: ARGOCD_HOSTNAME
                        valueFrom:
                          secretKeyRef:
                            name: rhtap-argocd-secret
                            key: hostname
                      - name: ARGOCD_TOKEN
                        valueFrom:
                          secretKeyRef:
                            name: rhtap-argocd-secret
                            key: api-token
                      - name: DEVELOPER_HUB_HOSTNAME
                        valueFrom:
                          secretKeyRef:
                            name: rhtap-developer-hub-secret
                            key: hostname
                      - name: PIPELINES_PAC_GH_SECRET
                        valueFrom:
                          secretKeyRef:
                            name: rhtap-pipelines-secret
                            key: webhook-github-secret
                      - name: PIPELINES_PAC_URL
                        valueFrom:
                          secretKeyRef:
                            name: rhtap-pipelines-secret
                            key: webhook-url
                      image: "registry.redhat.io/openshift4/ose-tools-rhel8:latest"
                      name: setup
                      script: |
                        #!/usr/bin/env bash
                        set -o errexit
                        set -o nounset
                        set -o pipefail
                
                        # Output information in YAML so that it can easily be
                        # post-processed if necessary.
                        cat << _EOF_
                        gitops:
                          api-token: \$ARGOCD_TOKEN
                          hostname: \$ARGOCD_HOSTNAME
                        developer-hub:
                          hostname: \$DEVELOPER_HUB_HOSTNAME
                        pipelines:
                          pipelines-as-code:
                            github:
                              # The docs URL explains how to setup the GitHub Application.
                              # Set dummy values for the homepage URL and webhook URL, and
                              # replace them with the final values after the chart is installed.
                              docs-url: https://pipelinesascode.com/docs/install/github_apps/
                              homepage-url: https://\$DEVELOPER_HUB_HOSTNAME
                              callback-url: https://\$DEVELOPER_HUB_HOSTNAME/api/auth/github/handler/frame
                              webhook-url: \$PIPELINES_PAC_URL
                              secret: \$PIPELINES_PAC_GH_SECRET
                        _EOF_
                      workingDir: /tmp
                
              EOF
              echo -n "."
              echo "OK"
        
            
                    
              DEV_NAMESPACE_LIST=(
               "rhtap-app-development" "rhtap-app-stage" "rhtap-app-prod"
              
              )
              
              echo -n "* Waiting for resources: "
              while ! kubectl get tasks "$CHART-dev-namespace-setup" >/dev/null 2>&1; do
                echo -n "_"
                sleep 2
              done
              echo "OK"
              
              for DEV_NAMESPACE in "${DEV_NAMESPACE_LIST[@]}"; do
                echo -n "* Creating '$DEV_NAMESPACE' namespace: "
                kubectl create namespace "$DEV_NAMESPACE" --dry-run=client -o yaml | kubectl apply -f - >/dev/null
                echo -n "."
                kubectl annotate namespace "$DEV_NAMESPACE" "argocd.argoproj.io/managed-by=$CHART-argocd" >/dev/null
                echo "OK"
                echo -n "* Configuring '$DEV_NAMESPACE' namespace: "
                cat << EOF | sed "s|^metadata:.*|\0\n  namespace: $DEV_NAMESPACE|" | kubectl create --filename - >/dev/null
              
              apiVersion: tekton.dev/v1
              kind: PipelineRun
              metadata:
                generateName: rhtap-dev-namespace-setup-
                annotations:
                  helm.sh/chart: "redhat-trusted-application-pipeline-0.1.0"
              spec:
                pipelineSpec:
                  tasks:
                    - name: configure-namespace
                      taskRef:
                        resolver: cluster
                        params:
                          - name: kind
                            value: task
                          - name: name
                            value: rhtap-dev-namespace-setup
                          - name: namespace
                            value: rhtap
              
              EOF
                echo "OK"
              done
              
            
        
              echo
              echo "Configuration successful"
        
                
        - name: configure-pipelines
          image: quay.io/redhat-appstudio/appstudio-utils:dbbdd82734232e6289e8fbae5b4c858481a7c057
          command:
            - /bin/bash
            - -c
            - |
              set -o errexit
              set -o nounset
              set -o pipefail
            
        
              CRD="tektonconfigs"
              echo -n "* Waiting for '$CRD' CRD: "
              while [ $(kubectl api-resources | grep -c "^$CRD ") = "0" ] ; do
                echo -n "."
                sleep 3
              done
              echo "OK"
        
              #
              # All actions MUST be idempotent
              #
              CHART="rhtap"
              PIPELINES_NAMESPACE="openshift-pipelines"
        
              echo -n "* Waiting for pipelines operator deployment: "
              until kubectl get namespace "$PIPELINES_NAMESPACE" >/dev/null 2>&1; do
                echo -n "."
                sleep 3
              done
              until kubectl get route -n "$PIPELINES_NAMESPACE" pipelines-as-code-controller >/dev/null 2>&1; do
                echo -n "."
                sleep 3
              done
              echo "OK"
        
              echo -n "* Update the TektonConfig resource: "
              until kubectl get tektonconfig config >/dev/null 2>&1; do
                echo -n "."
                sleep 3
              done
              kubectl patch tektonconfig config --type 'merge' --patch '        
                {
                  "spec": {
                    "pipeline": {
                      "enable-bundles-resolver": true,
                      "enable-cluster-resolver": true,
                      "enable-custom-tasks": true,
                      "enable-git-resolver": true,
                      "enable-hub-resolver": true,
                      "enable-tekton-oci-bundles": true
                    },
                    "chain": {
                      "artifacts.oci.storage": "oci",
                      "artifacts.pipelinerun.format": "in-toto",
                      "artifacts.pipelinerun.storage": "oci",
                      "artifacts.taskrun.format": "in-toto",
                      "artifacts.taskrun.storage": "oci",
                      "transparency.enabled": "true",
                      "transparency.url": "http://rekor-server.rhtap.svc"
                    },
                    "platforms": {
                      "openshift": {
                        "pipelinesAsCode": {
                          "settings": {
                            "remember-ok-to-test": "false"
                          }
                        }
                      }
                    }
                  }
                }
                ' >/dev/null
              echo "OK"
        
              echo -n "* Configuring Chains secret: "
              SECRET="signing-secrets"
              if [ "$(kubectl get secret -n "$PIPELINES_NAMESPACE" "$SECRET" -o jsonpath='{.data}' --ignore-not-found --allow-missing-template-keys)" == "" ]; then
                # Delete secret/signing-secrets if already exists since by default cosign creates immutable secrets
                echo -n "."
                kubectl delete secrets  -n "$PIPELINES_NAMESPACE" "$SECRET" --ignore-not-found=true
        
                # To make this run conveniently without user input let's create a random password
                echo -n "."
                RANDOM_PASS=$( openssl rand -base64 30 )
        
                # Generate the key pair secret directly in the cluster.
                # The secret should be created as immutable.
                echo -n "."
                env COSIGN_PASSWORD=$RANDOM_PASS cosign generate-key-pair "k8s://$PIPELINES_NAMESPACE/$SECRET" >/dev/null
              fi
              # If the secret is not marked as immutable, make it so.
              if [ "$(kubectl get secret -n "$PIPELINES_NAMESPACE" "$SECRET" -o jsonpath='{.immutable}')" != "true" ]; then
                echo -n "."
                kubectl patch secret -n "$PIPELINES_NAMESPACE" "$SECRET" --dry-run=client -o yaml \
                  --patch='{"immutable": true}' \
                | kubectl apply -f - >/dev/null
              fi
              echo "OK"
        
            
              echo -n "* Configuring Pipelines-as-Code: "
              if [ "$(kubectl get secret "$CHART-pipelines-secret" -o name --ignore-not-found | wc -l)" = "0" ]; then
                echo -n "."
                WEBHOOK_SECRET="\${GITHUB__APP__WEBHOOK_SECRET}"
                kubectl create secret generic "$CHART-pipelines-secret" \
                  --from-literal="webhook-github-secret=$WEBHOOK_SECRET" \
                  --from-literal="webhook-url=$(kubectl get routes -n "$PIPELINES_NAMESPACE" pipelines-as-code-controller -o jsonpath="https://{.spec.host}")" >/dev/null
              else
                WEBHOOK_SECRET="$(kubectl get secret "$CHART-pipelines-secret" ) -o jsonpath="{.data.webhook-github-secret}" | base64 -d"
              fi
              if [ "$(kubectl get secret -n "$PIPELINES_NAMESPACE" "pipelines-as-code-secret" -o name --ignore-not-found | wc -l)" = "0" ]; then
                echo -n "."
                kubectl -n "$PIPELINES_NAMESPACE" create secret generic pipelines-as-code-secret \
                  --from-literal github-application-id="${GITHUB__APP__APP_ID}" \
                  --from-literal github-private-key="$(echo "JHtHSVRIVUJfX0FQUF9fUFJJVkFURV9LRVl9Cg==" | base64 -d)" \
                  --from-literal webhook.secret="$WEBHOOK_SECRET" \
                  --dry-run=client -o yaml | kubectl apply -f - >/dev/null
              fi
              echo "OK"
            
        
              echo
              echo "Configuration successful"
        
                
        
        - name: configure-trusted-artifact-signer
          image: "registry.redhat.io/openshift4/ose-tools-rhel8:latest"
          command:
            - /bin/bash
            - -c
            - |
              set -o errexit
              set -o nounset
              set -o pipefail
          
        
              CHART="rhtap"
        
              echo -n "* Configure OIDC: "
            
              git clone https://github.com/securesign/sigstore-ocp.git >/dev/null
              echo -n "."
              oc apply --kustomize sigstore-ocp/keycloak/operator/base
              echo -n "."
              for CR in keycloaks keycloakclients keycloakrealms keycloakusers; do
                while [ $(kubectl api-resources | grep -c "^$CR ") = "0" ] ; do
                  echo -n "_"
                  sleep 2
                done
                echo -n "."
              done
              oc apply --kustomize sigstore-ocp/keycloak/resources/base --dry-run=client -o yaml
              oc apply --kustomize sigstore-ocp/keycloak/resources/base
              echo -n "."
              export FULCIO__OIDC__CLIENT_ID="trusted-artifact-signer"
              export FULCIO__OIDC__TYPE="email"
              FULCIO__OIDC__URL=""
              while [ -z "$FULCIO__OIDC__URL" ]; do
                FULCIO__OIDC__URL="$(kubectl get routes -n keycloak-system keycloak -o jsonpath="{.spec.host}" --ignore-not-found)"
                sleep 2
              done
              export FULCIO__OIDC__URL="https://$FULCIO__OIDC__URL/auth/realms/trusted-artifact-signer"
            
              export FULCIO__ORG_EMAIL="${TAS__SECURESIGN__FULCIO__ORG_EMAIL}"
              export FULCIO__ORG_NAME="${TAS__SECURESIGN__FULCIO__ORG_NAME}"
              echo "OK"
        
              CRDS=( securesigns )
              for CRD in "${CRDS[@]}"; do
                echo -n "* Waiting for '$CRD' CRD: "
                while [ $(kubectl api-resources | grep -c "^$CRD ") = "0" ] ; do
                  echo -n "_"
                  sleep 2
                done
                echo "OK"
              done
        
              echo -n "* Configure SecureSign instance: "
              cat <<EOF | kubectl apply -f - >/dev/null
              
              apiVersion: rhtas.redhat.com/v1alpha1
              kind: Securesign
              metadata:
                name: rhtap-securesign
                labels:
                  app.kubernetes.io/instance: securesign-sample
                  app.kubernetes.io/name: securesign-sample
                  app.kubernetes.io/part-of: trusted-artifact-signer
                namespace: rhtap
              spec:
                fulcio:
                  certificate:
                    commonName: fulcio.hostname
                    organizationEmail: ${FULCIO__ORG_EMAIL}
                    organizationName: ${FULCIO__ORG_NAME}
                  config:
                    OIDCIssuers:
                      "${FULCIO__OIDC__URL}":
                        ClientID: ${FULCIO__OIDC__CLIENT_ID}
                        IssuerURL: "${FULCIO__OIDC__URL}"
                        Type: ${FULCIO__OIDC__TYPE}
                  externalAccess:
                    enabled: true
                  monitoring: false
                rekor:
                  externalAccess:
                    enabled: true
                  signer:
                    kms: secret
                  monitoring: false
                trillian:
                  database:
                    create: true
                tuf:
                  externalAccess:
                    enabled: true
                  keys:
                    - name: rekor.pub
                    - name: ctfe.pub
                    - name: fulcio_v1.crt.pem
                  port: 80
              
              EOF
              echo "OK"
        
              echo
              echo "Configuration successful"
        
        
                
        
        - name: configure-trusted-profile-analyzer
          image: registry.redhat.io/openshift4/ose-tools-rhel8:latest
          command:
            - /bin/bash
            - -c
            - |
              set -o errexit
              set -o nounset
              set -o pipefail
          
        
              cd /tmp
        
              # Installing Helm...
              curl --fail --silent --show-error --location \
                https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 \
                  | bash
              
              # Storing the attributes ".trusted-profile-analyzer" from "values.yaml" as a
              # standalone file, employed later on as input for the trustification Charts.
              declare -r TRUSTIFICATION_VALUES="/tmp/trustification-values.yaml"
          
              cat <<EOF >${TRUSTIFICATION_VALUES}
              ---
              eventBus:
                bootstrapServers: tpa-infrastructure-kafka:9092
                config:
                  mechanism: PLAIN
                  password:
                    valueFrom:
                      secretKeyRef:
                        key: client-passwords
                        name: tpa-infrastructure-kafka-user-passwords
                  securityProtocol: SASL_PLAINTEXT
                  username: user1
                type: kafka
              guac:
                database:
                  host: tpa-infrastructure-postgresql
                  name: guac
                  password: ${TPA__GUAC__PASSWORD}
                  sslMode: disable
                  username: guac
                initDatabase:
                  host: tpa-infrastructure-postgresql
                  name: postgres
                  password:
                    valueFrom:
                      secretKeyRef:
                        key: postgres-password
                        name: tpa-infrastructure-postgresql
                  sslMode: disable
                  username: postgres
              ingress:
                className: openshift-default
              kafka:
                controller:
                  containerSecurityContext:
                    enabled: false
                  podSecurityContext:
                    enabled: false
                enabled: true
                kraft:
                  clusterId: 3nA2qspzReOmcxqlkmITAA
                provisioning:
                  containerSecurityContext:
                    enabled: false
                  podSecurityContext:
                    enabled: false
              keycloak:
                auth:
                  adminPassword: ${TPA__KEYCLOAK__ADMIN_PASSWORD}
                  adminUser: admin
                containerSecurityContext:
                  enabled: false
                enabled: true
                ingress:
                  annotations:
                    route.openshift.io/termination: reencrypt
                  enabled: true
                  ingressClassName: openshift-default
                  servicePort: https
                podSecurityContext:
                  enabled: false
                postgresql:
                  auth:
                    password: ${TPA__POSTGRES__TPA_PASSWORD}
                    postgresPassword: ${TPA__POSTGRES__POSTGRES_PASSWORD}
                    username: trusted-profile-analyzer
                  primary:
                    containerSecurityContext:
                      enabled: false
                    podSecurityContext:
                      enabled: false
                production: true
                proxy: reencrypt
                service:
                  annotations:
                    service.beta.openshift.io/serving-cert-secret-name: sso-tls
                tls:
                  enabled: true
                  existingSecret: sso-tls
                  usePem: true
              minio:
                containerSecurityContext:
                  enabled: false
                enabled: true
                persistence:
                  size: 5Gi
                podSecurityContext:
                  enabled: false
                rootPassword: ${TPA__MINIO__ROOT_PASSWORD}
              modules:
                bombasticWalker:
                  sources:
                    redhat:
                      acceptV3Signatures: true
                      fixLicenses: true
                      job:
                        schedule: 0 * * * *
                      signingKeyUrl: https://access.redhat.com/security/data/97f5eac4.txt#77E79ABE93673533ED09EBE2DCE3823597F5EAC4
                      url: https://access.redhat.com/security/data/sbom/beta/
                vexinationWalker:
                  sources:
                    redhat:
                      acceptV3Signatures: true
                      ignoreDistributions:
                      - https://access.redhat.com/security/data/csaf/v2/advisories/
                      job:
                        schedule: 0 * * * *
                      url: https://www.redhat.com/.well-known/csaf/provider-metadata.json
              oidc:
                clients:
                  frontend: {}
                  testingManager:
                    clientSecret:
                      value: ${TPA__OIDC__TESTING_MANAGER_CLIENT_SECRET}
                  testingUser:
                    clientSecret:
                      value: ${TPA__OIDC__TESTING_USER_CLIENT_SECRET}
                  walker:
                    clientSecret:
                      value: ${TPA__OIDC__WALKER_CLIENT_SECRET}
              openshift:
                useServiceCa: true
              storage:
                accessKey:
                  valueFrom:
                    secretKeyRef:
                      key: root-user
                      name: tpa-infrastructure-minio
                endpoint: http://tpa-infrastructure-minio:9000
                secretKey:
                  valueFrom:
                    secretKeyRef:
                      key: root-password
                      name: tpa-infrastructure-minio
              tracing:
                enabled: false
              EOF
          
        
              # Same namespace where the "rhtap" is being released
              declare -r NAMESPACE="rhtap"
              # Primary openshift domain name, other apps will be exposed via wildcards
              declare -r INGRESS_DOMAIN=$(
                  oc --namespace=openshift-ingress-operator \
                    get ingresscontrollers.operator.openshift.io default \
                      --output=jsonpath='{.status.domain}'
              )
              # suffix for applications with a fully qualified domain
              declare -r APP_DOMAIN="-${NAMESPACE}.${INGRESS_DOMAIN}"
        
              # Cloning the trustification repository, and resetting to a known commit
              # before rollout.
              git clone https://github.com/trustification/trustification.git
              pushd trustification &&
                # Desired commit for trustification charts.
                git reset --hard 9abcf0a6 &&
                  # Adding the bitnami repository for "trustification-infrastructure"
                  # dependencies.
                  helm repo add bitnami https://charts.bitnami.com/bitnami
        
                  # Preparing Helm dependencies for both charts...
                  pushd deploy/k8s/charts/trustification-infrastructure &&
                    helm dependency build
                  popd
                  pushd deploy/k8s/charts/trustification &&
                    helm dependency build
                  popd
        
                  pushd deploy/k8s &&
                    # Installing the infrastructure needed for trustification first, and
                    # only when infrastructure is ready the trustification rollout
                    # starts...
                    if ! helm upgrade \
                      --install \
                      --namespace=${NAMESPACE} \
                      --timeout=10m \
                      --values=${TRUSTIFICATION_VALUES} \
                      --set-string=keycloak.ingress.hostname=sso${APP_DOMAIN} \
                      --set-string=appDomain=${APP_DOMAIN} \
                      --debug \
                      tpa-infrastructure \
                      charts/trustification-infrastructure; then
                      echo "ERROR: Installing trustification-infrastructure chart!"
                      exit 1
                    fi
                  
                    if ! helm upgrade \
                        --install \
                        --namespace=${NAMESPACE} \
                        --timeout=10m \
                        --values=${TRUSTIFICATION_VALUES} \
                        --set-string=keycloak.ingress.hostname=sso${APP_DOMAIN} \
                        --set-string appDomain=${APP_DOMAIN} \
                        --debug \
                        tpa \
                        charts/trustification; then
                      echo "ERROR: Installing trustification chart!"
                      exit 1
                    fi
                  popd
              popd
              echo "OK"
        
              echo
              echo "Configuration successful"
        
        
      restartPolicy: Never
      serviceAccountName: helm-manager
---
# Source: redhat-trusted-application-pipeline/templates/tests/test.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: "rhtap-installer-test"
  labels:
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/instance: "installer"
    app.kubernetes.io/version: 1.1.0
    helm.sh/chart: "redhat-trusted-application-pipeline-0.1.0"
  annotations:
    # This is what defines this resource as a hook. Without this line, the
    # job is considered part of the release.
    helm.sh/hook: test
spec:
  template:
    metadata:
      name: "installer-test"
      labels:
        app.kubernetes.io/managed-by: "Helm"
        app.kubernetes.io/instance: "installer"
        helm.sh/chart: "redhat-trusted-application-pipeline-0.1.0"
    spec:
      automountServiceAccountToken: true
      containers:
                
        - name: test-namespace
          image: "registry.redhat.io/openshift4/ose-tools-rhel8:latest"
          command:
            - /bin/bash
            - -c
            - |
              set -o errexit
              set -o nounset
              set -o pipefail
        
              pipeline_id="$(cat << EOF | kubectl create -f - | cut -d' ' -f 1
                      
                apiVersion: tekton.dev/v1
                kind: PipelineRun
                metadata:
                  generateName: rhtap-test-config-
                  annotations:
                    helm.sh/chart: "redhat-trusted-application-pipeline-0.1.0"
                spec:
                  pipelineSpec:
                    tasks:
                    - name: argocd-login-check
                      taskRef:
                        resolver: cluster
                        params:
                          - name: kind
                            value: task
                          - name: name
                            value: argocd-login-check
                          - name: namespace
                            value: rhtap
                
              EOF
              )"
              echo -n "* Pipeline $pipeline_id: "
              while ! kubectl get "$pipeline_id" | grep --extended-regex --quiet " False | True "; do
                echo -n "."
                sleep 2
              done
              if kubectl get "$pipeline_id" | grep --quiet " True "; then
                kubectl delete "$pipeline_id" > /dev/null
                echo "OK"
              else
                echo "Failed"
                exit 1
              fi
          resources:
            limits:
              cpu: 100m
              memory: 256Mi
        
                
        - name: test-openshift-gitops
          image: "registry.redhat.io/openshift4/ose-tools-rhel8:latest"
          command:
            - /bin/bash
            - -c
            - |
              set -o errexit
              set -o nounset
              set -o pipefail
        
              ERRORS=()
        
              rollout_status() {
                local namespace="${1}"
                local deployment="${2}"
        
                if ! kubectl --namespace="${namespace}" --timeout="5m" \
                  rollout status deployment "${deployment}"; then
                  fail "'${namespace}/${deployment}' is not deployed as expected!"
                fi
              }
        
              check_gitops_operator_health() {
                echo "[INFO] Checking OpenShift GitOps health..."
        
                # wait until tekton pipelines operator is created
                echo "Waiting for OpenShift Pipelines Operator to be created..."
                timeout 2m bash <<-EOF
                until oc get deployment openshift-gitops-operator-controller-manager -n openshift-operators; do
                  echo -n "."
                  sleep 5
                done
              EOF
                oc rollout status -n openshift-operators deployment/openshift-gitops-operator-controller-manager --timeout 10m
        
                # wait until all the deployments in the openshift-gitops namespace are ready:
                rollout_status "openshift-gitops" "cluster"
                rollout_status "openshift-gitops" "kam"
                rollout_status "openshift-gitops" "openshift-gitops-applicationset-controller"
                rollout_status "openshift-gitops" "openshift-gitops-dex-server"
                rollout_status "openshift-gitops" "openshift-gitops-redis"
                rollout_status "openshift-gitops" "openshift-gitops-repo-server"
                rollout_status "openshift-gitops" "openshift-gitops-server"
        
        
                # Check argocd instance creation
                oc delete ns test-argocd --ignore-not-found --wait
                oc create ns test-argocd
        
                cat << EOF | oc apply -f -
                apiVersion: argoproj.io/v1beta1
                kind: ArgoCD
                metadata:
                    name: argocd
                    namespace: test-argocd
              EOF
        
                while [ "$(oc -n test-argocd get pod | grep -c argocd-)" -ne 4 ]; do
                  sleep 5
                done
                oc wait --for=condition=Ready -n test-argocd pod --timeout=15m  -l 'app.kubernetes.io/name in (argocd-application-controller,argocd-redis,argocd-repo-server,argocd-server)'
        
                oc delete ns test-argocd
              }
        
              check_rhtap_argocd_health() {
                echo "[INFO] Checking RHTAP ArgoCD instance health..."
                RHTAP_ARGOCD_INSTANCE="rhtap-argocd"
                NAMESPACE="rhtap"
                PREFIX="$RHTAP_ARGOCD_INSTANCE-$NAMESPACE-argocd-"
                # Make sure the rhtap ArgoCD instance has permission on the cluster
                echo -n "* ArgoCD clusterroles: "
                if [ "$(oc get clusterroles -o name | grep -c "/$PREFIX")" = "3" ]; then
                  echo "OK"
                else
                  echo "FAIL"
                  ERRORS+=("ClusterRoles for ArgoCD not found.")
                fi
                echo -n "* ArgoCD clusterrolebindings: "
                if [ "$(oc get clusterrolebindings -o name | grep -c "/$PREFIX")" = "3" ]; then
                  echo "OK"
                else
                  echo "FAIL"
                  ERRORS+=("ClusterRoleBindings for ArgoCD not found.")
                fi
              }
        
              check_gitops_operator_health
              check_rhtap_argocd_health
        
              if [ "${#ERRORS[@]}" != "0" ]; then
                for MSG in "${ERRORS[@]}"; do
                  echo "[ERROR]$MSG" >&2
                done
                exit 1
              fi
          resources:
            limits:
              cpu: 100m
              memory: 256Mi
        
                
        - name: test-openshift-pipelines
          image: "registry.redhat.io/openshift4/ose-tools-rhel8:latest"
          command:
            - /bin/bash
            - -c
            - |
              set -o errexit
              set -o nounset
              set -o pipefail
        
              rollout_status() {
                local namespace="${1}"
                local deployment="${2}"
        
                if ! kubectl --namespace="${namespace}" --timeout="5m" \
                  rollout status deployment "${deployment}"; then
                  fail "'${namespace}/${deployment}' is not deployed as expected!"
                fi
              }
              
              check_rhtap_pipelines_health() {
                echo "[INFO] Checking OpenShift Pipelines health..."
        
                # wait until tekton pipelines operator is created
                echo "Waiting for OpenShift Pipelines Operator to be created..."
                timeout 2m bash <<-EOF
                until oc get deployment openshift-pipelines-operator -n openshift-operators; do
                  echo -n "."
                  sleep 5
                done
              EOF
                oc rollout status -n openshift-operators deployment/openshift-pipelines-operator --timeout 10m
        
                # wait until clustertasks tekton CRD is properly deployed
                timeout 10m bash <<-EOF
                until oc get crd tasks.tekton.dev; do
                  sleep 5
                done
              EOF
        
                timeout 2m bash <<-EOF
                until oc get deployment tekton-pipelines-controller -n openshift-pipelines; do
                  sleep 5
                done
              EOF
                rollout_status "openshift-pipelines" "tekton-pipelines-controller"
                rollout_status "openshift-pipelines" "tekton-pipelines-webhook"
              }
        
              check_rhtap_pipelines_health
          resources:
            limits:
              cpu: 100m
              memory: 256Mi
        
      restartPolicy: Never
      serviceAccountName: helm-manager
